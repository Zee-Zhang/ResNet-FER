{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LkQgS1MUXKRV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "model = models.resnet50(pretrained=True).to(device)\n",
    "freeze_layers(model, 148)\n",
    "\n",
    "model.fc = nn.Linear(in_features=2048, out_features=8).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KssiB-Atahk6"
   },
   "outputs": [],
   "source": [
    "def freeze_layers(model, cutoff):\n",
    "    count = 0\n",
    "    for param in model.parameters():\n",
    "        count += 1\n",
    "        if count < cutoff:\n",
    "            param.requires_grad = False\n",
    "        else:\n",
    "            param.requires_grad = True\n",
    "\n",
    "def view_params(model):\n",
    "    for param in model.parameters():\n",
    "        print (param.shape, param.requires_grad)\n",
    "\n",
    "def calculate_accuracy(fx, y):\n",
    "    preds = fx.max(1, keepdim=True)[1]\n",
    "    correct = preds.eq(y.view_as(preds)).sum()\n",
    "    print (correct)\n",
    "    acc = correct.float()/preds.shape[0]\n",
    "    return acc\n",
    "\n",
    "def train(model, device, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    for (x, y) in iterator:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad() \n",
    "        fx = model(x)\n",
    "        loss = criterion(fx, y)\n",
    "        acc = calculate_accuracy(fx, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, device, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            fx = model(x)\n",
    "            loss = criterion(fx, y)\n",
    "            acc = calculate_accuracy(fx, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D4rZwz7eYabd"
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                           transforms.RandomHorizontalFlip(),\n",
    "                           transforms.RandomRotation(10),\n",
    "                           transforms.RandomCrop((224, 224), pad_if_needed=True),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
    "                       ])\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_data = datasets.ImageFolder('train', train_transforms)\n",
    "print(f'Number of training examples: {len(train_data)}')\n",
    "train_iterator = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\n",
    "#valid_iterator = torch.utils.data.DataLoader(valid_data, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yx7BSrRakaw"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "SAVE_DIR = 'models'\n",
    "MODEL_SAVE_PATH = os.path.join(SAVE_DIR, 'resnet18-dogs-vs-cats.pt')\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "if not os.path.isdir(f'{SAVE_DIR}'):\n",
    "    os.makedirs(f'{SAVE_DIR}')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(model, device, train_iterator, optimizer, criterion)\n",
    "#     valid_loss, valid_acc = evaluate(model, device, valid_iterator, criterion)\n",
    "    \n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    \n",
    "#     print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:05.2f}% ) #| Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:05.2f}% |')\n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:05.2f}% ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "F0tRKa0byMzU",
    "outputId": "7f355203-a288-4b78-ff56-a04e421747ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(59, device='cuda:0')\n",
      "tensor(61, device='cuda:0')\n",
      "tensor(60, device='cuda:0')\n",
      "tensor(62, device='cuda:0')\n",
      "tensor(59, device='cuda:0')\n",
      "tensor(64, device='cuda:0')\n",
      "tensor(14, device='cuda:0')\n",
      "| Test Loss: 0.183 | Test Acc: 95.76% |\n"
     ]
    }
   ],
   "source": [
    "test_transforms = transforms.Compose([\n",
    "                           transforms.CenterCrop((224, 224)),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
    "                       ])\n",
    "\n",
    "test_data = datasets.ImageFolder('test', test_transforms)\n",
    "test_iterator = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, device, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:05.2f}% |')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(60, device='cuda:0')\n",
      "tensor(64, device='cuda:0')\n",
      "tensor(63, device='cuda:0')\n",
      "tensor(62, device='cuda:0')\n",
      "tensor(60, device='cuda:0')\n",
      "tensor(61, device='cuda:0')\n",
      "tensor(63, device='cuda:0')\n",
      "tensor(54, device='cuda:0')\n",
      "tensor(64, device='cuda:0')\n",
      "tensor(17, device='cuda:0')\n",
      "| Test Loss: 0.148 | Test Acc: 95.54% |\n"
     ]
    }
   ],
   "source": [
    "PATH = \"./dex-1.pt\"\n",
    "\n",
    "import torchvision.models as models\n",
    "from PIL import Image, ImageDraw\n",
    "from torch.autograd import Variable\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model = models.resnet50(pretrained=True).to(device)\n",
    "\n",
    "model.fc = nn.Linear(in_features=2048, out_features=8).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.load_state_dict(torch.load(PATH))#.to(device)\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.CenterCrop((224, 224)),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
    "                       ])\n",
    "\n",
    "test_data = datasets.ImageFolder('test', test_transforms)\n",
    "test_iterator = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "test_loss, test_acc = evaluate(model, device, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:05.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bfbJiECdZXXD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sadness'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = \"./clara.jpg\"\n",
    "imsize = 256\n",
    "loader = transforms.Compose([transforms.Scale(imsize), transforms.ToTensor()])\n",
    "\n",
    "def predict(model, image_path, test_data):\n",
    "    image = Image.open(image_path)\n",
    "    image = loader(image).float()\n",
    "    image = Variable(image, requires_grad=True)\n",
    "    image = image.unsqueeze(0).to(device)    \n",
    "    key = torch.argmax(model(image).data[0]).item()\n",
    "    response = test_data.class_to_idx\n",
    "    answer = {value: key for key, value in response.items()}[key]\n",
    "    return answer\n",
    "\n",
    "predict(model, img_path, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4nVBZBWo3UNU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-SmXEBAPXqq5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lbZO8Gr_YLh3",
    "outputId": "5777ffb6-6b95-4ccc-f7f8-d51460ba77b3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rt5hb-tmYevZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqsASPG7YfjY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "heKIwmckmnfp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yr9_9z_jagNY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i6Ri3wFryTbn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2MX4MBmJyJdU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet_FER.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
